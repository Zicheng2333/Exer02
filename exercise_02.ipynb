{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 02: Multi-class Classification \n",
    "In this exercise, you will train a deep model on the CIFAR10 from the scratch using PyTorch. The following tasks should be done:\n",
    "- Task 1: per batch training/testing\n",
    "- Task 2: Instance inference and visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import os.path as osp\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# random seed\n",
    "SEED = 1 \n",
    "NUM_CLASS = 10\n",
    "\n",
    "# Training\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 30\n",
    "EVAL_INTERVAL=1\n",
    "SAVE_DIR = './log'\n",
    "\n",
    "# Optimizer\n",
    "LEARNING_RATE = 1e-1\n",
    "MOMENTUM = 0.9\n",
    "STEP=5\n",
    "GAMMA=0.5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# cifar10 transform\n",
    "transform_cifar10_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "#随机裁剪并进行边缘填充，随机翻转，转换为张量，图像规范化\n",
    "#transforms.Compose可以进行多个数据转换操作\n",
    "\n",
    "transform_cifar10_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "#测试不需要对图像进行处理\n",
    "\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(root='../data', train=True,\n",
    "                                        download=True, transform=transform_cifar10_train)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "test_set = torchvision.datasets.CIFAR10(root='../data', train=False,\n",
    "                                       download=True, transform=transform_cifar10_test)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 4, 3)  \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(4, 8, 3)  \n",
    "        self.fc1 = nn.Linear(8 * 6 * 6, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 8 * 6 * 6)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = models.resnet50(pretrained= True)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(2048, 32), \n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32, 10)  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=32, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=32, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model = ConvNet()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=STEP, gamma=GAMMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: per batch training/testing\n",
    "---\n",
    "\n",
    "Please denfine two function named ``train_batch`` and ``test_batch``. These functions are essential for training and evaluating machine learning models using batched data from dataloaders.\n",
    "\n",
    "**To do**: \n",
    "1. Define the loss function i.e [nn.CrossEntropyLoss()](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html).\n",
    "2. Take the image as the input and generate the output using the pre-defined SimpleNet.\n",
    "3. Calculate the loss between the output and the corresponding label using the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "##################### Write your answer here ##################\n",
    "# Define the loss function\n",
    "criterion = nn.CrossEntropyLoss(reduction='mean')\n",
    "###############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "def train_batch(model, image, target):\n",
    "    \"\"\"\n",
    "    Perform one training batch iteration.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The machine learning model to train.\n",
    "        image (torch.Tensor): Batch of input data (images).\n",
    "        target (torch.Tensor): Batch of target labels.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Model output (predictions) for the batch.\n",
    "        torch.Tensor: Loss value calculated by the defined loss function loss_fn().\n",
    "    \"\"\"\n",
    "    \n",
    "    ##################### Write your answer here ##################\n",
    "    output = model(image)\n",
    "    loss = criterion(output,target)\n",
    "    ###############################################################\n",
    "\n",
    "    return output, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def test_batch(model, image, target):\n",
    "    \"\"\"\n",
    "    Perform one testing batch iteration.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The machine learning model to evaluate.\n",
    "        image (torch.Tensor): Batch of input data (images).\n",
    "        target (torch.Tensor): Batch of target labels.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Model output (predictions) for the batch.\n",
    "        torch.Tensor: Loss value calculated for the batch.\n",
    "    \"\"\"\n",
    "\n",
    "    ##################### Write your answer here ##################\n",
    "    output = model(image)\n",
    "    loss = criterion(output,target)\n",
    "    ###############################################################\n",
    "\n",
    "    return output, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30 Train Loss: 0.0154 Acc: 0.2887\n",
      "Begin test......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:11<05:23, 11.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0160 Acc: 0.2980\n",
      "Epoch: 2/30 Train Loss: 0.0148 Acc: 0.3339\n",
      "Begin test......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2/30 [00:21<05:03, 10.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0152 Acc: 0.3238\n",
      "Epoch: 3/30 Train Loss: 0.0144 Acc: 0.3545\n",
      "Begin test......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3/30 [00:32<04:48, 10.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0151 Acc: 0.3381\n",
      "Epoch: 4/30 Train Loss: 0.0145 Acc: 0.3525\n",
      "Begin test......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4/30 [00:42<04:36, 10.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0153 Acc: 0.3340\n",
      "Epoch: 5/30 Train Loss: 0.0145 Acc: 0.3513\n",
      "Begin test......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5/30 [00:53<04:25, 10.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0156 Acc: 0.3179\n",
      "Epoch: 6/30 Train Loss: 0.0134 Acc: 0.3974\n",
      "Begin test......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 6/30 [01:03<04:14, 10.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0138 Acc: 0.3872\n",
      "Epoch: 7/30 Train Loss: 0.0130 Acc: 0.4135\n",
      "Begin test......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7/30 [01:14<04:03, 10.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0137 Acc: 0.4007\n",
      "Epoch: 8/30 Train Loss: 0.0130 Acc: 0.4201\n",
      "Begin test......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 8/30 [01:25<03:52, 10.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0136 Acc: 0.4062\n",
      "Epoch: 9/30 Train Loss: 0.0129 Acc: 0.4237\n",
      "Begin test......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 9/30 [01:35<03:41, 10.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0136 Acc: 0.3975\n",
      "Epoch: 10/30 Train Loss: 0.0129 Acc: 0.4218\n",
      "Begin test......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 10/30 [01:46<03:31, 10.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0135 Acc: 0.4115\n",
      "Epoch: 11/30 Train Loss: 0.0123 Acc: 0.4495\n",
      "Begin test......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 11/30 [01:56<03:20, 10.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0126 Acc: 0.4442\n",
      "Epoch: 12/30 Train Loss: 0.0122 Acc: 0.4491\n",
      "Begin test......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 12/30 [02:07<03:09, 10.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0128 Acc: 0.4425\n",
      "Epoch: 13/30 Train Loss: 0.0122 Acc: 0.4494\n",
      "Begin test......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 13/30 [02:17<02:59, 10.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0131 Acc: 0.4471\n",
      "Epoch: 14/30 Train Loss: 0.0121 Acc: 0.4521\n",
      "Begin test......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 14/30 [02:28<02:49, 10.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0128 Acc: 0.4416\n",
      "Epoch: 15/30 Train Loss: 0.0121 Acc: 0.4554\n",
      "Begin test......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 15/30 [02:39<02:38, 10.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0128 Acc: 0.4474\n",
      "Epoch: 16/30 Train Loss: 0.0119 Acc: 0.4652\n",
      "Begin test......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 16/30 [02:49<02:28, 10.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0123 Acc: 0.4546\n",
      "Epoch: 17/30 Train Loss: 0.0118 Acc: 0.4665\n",
      "Begin test......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 17/30 [03:00<02:17, 10.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0124 Acc: 0.4455\n",
      "Epoch: 18/30 Train Loss: 0.0118 Acc: 0.4664\n",
      "Begin test......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 18/30 [03:10<02:06, 10.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0127 Acc: 0.4439\n",
      "Epoch: 19/30 Train Loss: 0.0118 Acc: 0.4671\n",
      "Begin test......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 19/30 [03:21<01:56, 10.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0126 Acc: 0.4625\n",
      "Epoch: 20/30 Train Loss: 0.0118 Acc: 0.4686\n",
      "Begin test......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 20/30 [03:31<01:45, 10.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0128 Acc: 0.4538\n",
      "Epoch: 21/30 Train Loss: 0.0116 Acc: 0.4744\n",
      "Begin test......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 21/30 [03:42<01:35, 10.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0125 Acc: 0.4561\n",
      "Epoch: 22/30 Train Loss: 0.0116 Acc: 0.4799\n",
      "Begin test......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 22/30 [03:53<01:24, 10.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0122 Acc: 0.4651\n",
      "Epoch: 23/30 Train Loss: 0.0116 Acc: 0.4777\n",
      "Begin test......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 23/30 [04:03<01:14, 10.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0122 Acc: 0.4700\n",
      "Epoch: 24/30 Train Loss: 0.0115 Acc: 0.4786\n",
      "Begin test......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 24/30 [04:14<01:03, 10.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0122 Acc: 0.4599\n",
      "Epoch: 25/30 Train Loss: 0.0116 Acc: 0.4780\n",
      "Begin test......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 25/30 [04:24<00:52, 10.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0121 Acc: 0.4708\n",
      "Epoch: 26/30 Train Loss: 0.0114 Acc: 0.4852\n",
      "Begin test......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 26/30 [04:35<00:42, 10.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0123 Acc: 0.4715\n",
      "Epoch: 27/30 Train Loss: 0.0115 Acc: 0.4835\n",
      "Begin test......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 27/30 [04:45<00:31, 10.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0121 Acc: 0.4754\n",
      "Epoch: 28/30 Train Loss: 0.0115 Acc: 0.4830\n",
      "Begin test......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 28/30 [04:56<00:21, 10.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0123 Acc: 0.4564\n",
      "Epoch: 29/30 Train Loss: 0.0115 Acc: 0.4812\n",
      "Begin test......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 29/30 [05:07<00:10, 10.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0121 Acc: 0.4689\n",
      "Epoch: 30/30 Train Loss: 0.0115 Acc: 0.4827\n",
      "Begin test......\n",
      "Test Loss: 0.0124 Acc: 0.4605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [05:18<00:00, 10.60s/it]\n"
     ]
    }
   ],
   "source": [
    "training_loss = []\n",
    "training_acc = []\n",
    "testing_loss = []\n",
    "testing_acc = []\n",
    "\n",
    "for epoch in tqdm(range(NUM_EPOCHS)):\n",
    "    model.train()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    ##########################\n",
    "    ### Training\n",
    "    ##########################\n",
    "\n",
    "    running_cls_loss = 0.0\n",
    "    running_cls_corrects = 0\n",
    "\n",
    "    for batch_idx, (image, target) in enumerate(train_dataloader):\n",
    "\n",
    "        image = image.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # train model\n",
    "        outputs, loss = train_batch(model, image, target)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        \n",
    "        loss_data = loss.data.item()\n",
    "        if np.isnan(loss_data):\n",
    "            raise ValueError('loss is nan while training')\n",
    "        running_cls_loss += loss.item()\n",
    "        running_cls_corrects += torch.sum(preds == target.data)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    epoch_loss = running_cls_loss / len(train_set)\n",
    "    epoch_acc = running_cls_corrects.double() / len(train_set)\n",
    "\n",
    "    print(f'Epoch: {epoch+1}/{NUM_EPOCHS} Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "    training_loss.append(epoch_loss)\n",
    "    training_acc.append(epoch_acc.cpu().detach().numpy())\n",
    "\n",
    "    # change learning rate\n",
    "    scheduler.step()\n",
    "\n",
    "\n",
    "    ##########################\n",
    "    ### Testing\n",
    "    ##########################\n",
    "    # # eval model during training or in the last epoch\n",
    "    if (epoch + 1) % EVAL_INTERVAL == 0 or (epoch +1) == NUM_EPOCHS:\n",
    "        print('Begin test......')\n",
    "        model.eval()\n",
    "    \n",
    "        val_loss = 0.0\n",
    "        val_corrects = 0\n",
    "\n",
    "        for batch_idx, (image, target) in enumerate(test_dataloader):\n",
    "\n",
    "            image = image.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            # test model\n",
    "            outputs, loss = test_batch(model, image, target)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            val_corrects += torch.sum(preds == target.data)\n",
    "\n",
    "        val_loss = val_loss / len(test_set)\n",
    "        val_acc = val_corrects.double() / len(test_set)\n",
    "        print(f'Test Loss: {val_loss:.4f} Acc: {val_acc:.4f}')\n",
    "        testing_loss.append(val_loss)\n",
    "        testing_acc.append(val_acc.cpu().detach().numpy())\n",
    "\n",
    "        # save the model in last epoch\n",
    "        if (epoch +1) == NUM_EPOCHS:\n",
    "            \n",
    "            state = {\n",
    "            'state_dict': model.state_dict(),\n",
    "            'acc': epoch_acc,\n",
    "            'epoch': (epoch+1),\n",
    "            }\n",
    "\n",
    "            # check the dir\n",
    "            if not os.path.exists(SAVE_DIR):\n",
    "                os.makedirs(SAVE_DIR)\n",
    "\n",
    "            # save the state\n",
    "            torch.save(state, osp.join(SAVE_DIR, 'checkpoint_%s.pth' % (str(epoch+1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Instance inference\n",
    "---\n",
    "The task is to visualizes an image along with model prediction and class probabilities.\n",
    "\n",
    "**To do**: \n",
    "1. Calculate the prediction and the probabilities for each class.\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "inputs, classes = next(iter(test_dataloader))\n",
    "input = inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4, 3, 8, 8, 8, 4, 7, 0, 3, 9, 5, 8, 7, 3, 1, 7], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "##################### Write your answer here ##################\n",
    "# input: image, model\n",
    "# outputs: predict_label, probabilities\n",
    "# predict_label is the index (or label) of the class with the highest probability from the probabilities.\n",
    "###############################################################\n",
    "\n",
    "probabilities = F.softmax(model(image),dim=1)\n",
    "predict_label = torch.argmax(probabilities,dim=1)    \n",
    "print(predict_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print probabilities for each class:\n",
      "airplane: 0.0036\n",
      "automobile: 0.0034\n",
      "bird: 0.0047\n",
      "cat: 0.0251\n",
      "deer: 0.0216\n",
      "dog: 0.0669\n",
      "frog: 0.0029\n",
      "horse: 0.8604\n",
      "ship: 0.0008\n",
      "truck: 0.0106\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(predict_label)):\n",
    "    predicted_class = class_names[predict_label[i].item()]\n",
    "    predicted_probability = probabilities[i][predict_label[i]].item()\n",
    "    \n",
    "image = input.numpy().transpose((1, 2, 0))\n",
    "plt.imshow(image)\n",
    "plt.text(17, 30, f'Predicted Class: {predicted_class}\\nProbability: {predicted_probability:.2f}', \n",
    "            color='white', backgroundcolor='black', fontsize=8)\n",
    "plt.show()\n",
    "\n",
    "# Print probabilities for each class\n",
    "print('Print probabilities for each class:')\n",
    "for i in range(len(class_names)):\n",
    "    print(f'{class_names[i]}: {probabilities[15][i]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
